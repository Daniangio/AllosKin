# Sampling Explorer Plot Guide

This guide explains what each plot in the Sampling Explorer shows, how to interpret it, and what failures it diagnoses.

## Big picture: what we are comparing

All plots compare distributions of reduced microstates `x_r ∈ {1,…,K_r}` generated by:

- **MD**: reference in the reduced space (depends on clustering quality).
- **Gibbs**: correct Boltzmann sampling of the learned Potts model `p(x) ∝ exp(-βE(x))`.
- **SA/QUBO**: heuristic sampler without guaranteed Boltzmann distribution; often needs a calibrated `β_eff`.

Interpretation shortcuts:
- **Gibbs vs MD is bad** → representation or model fit is likely the issue.
- **SA vs Gibbs is bad** → sampler/encoding/penalty/schedule issue.
- **SA vs MD is bad but Gibbs vs MD is good** → clearly a sampler issue.

## Residue + edge diagnostics (macro panel)

### Residue barcode (JS divergence per residue)
Shows per-residue Jensen–Shannon (JS) divergence between two sources.

- **Low** JS (near 0) → distributions match.
- **High** JS → one source over/under-samples some states.

Use it to spot *which residues* are failing.

### Top residues
Lists the largest JS outliers. These are the residues most responsible for mismatch.

### Edge barcode (JS2 per edge)
Shows JS divergence on **pairwise** distributions `p(x_r, x_s)` for each edge.

Why it matters: a sampler can match single-residue marginals but still fail correlations.

- If **edge JS2 is high** but residue JS is low → correlations are wrong.

### Top edges
Lists edges with the highest pairwise mismatch.

### Edge heatmap
Heatmap of pairwise divergence across residue pairs. Useful for spotting localized coupling errors.

### Edge mismatch vs strength
Scatter of JS2 vs |J|. If strong couplings (large |J|) have high JS2, the sampler is likely failing to respect constraints.

## Energy histogram

Compares energy distributions of samples for each source.

What to look for:
- **SA higher energy** than Gibbs → SA is effectively “hotter”.
- **SA shape differs** from Gibbs even after `β_eff` → not just a temperature mismatch (sampling bias).

## Cross-likelihood classification (distributions + separability matrices)

**Purpose:** measure how well each sample’s distribution aligns with MD fit frames and how separable distributions are from each other.

The panel shows:

1) **Single distribution per sample** (left)
   - Each histogram is the Δ log-likelihood distribution for that sample.
   - MD fit frames are shown once (MD reference), Gibbs/SA samples once each.

2) **AUC separability matrix** (right, top)
   - Pairwise AUC computed between distributions.
   - AUC near **1** means row distribution tends to be larger than column distribution.
   - AUC near **0.5** means the two distributions overlap strongly.

3) **Δ mean separability matrix** (right, bottom)
   - Pairwise mean difference (row mean − column mean).
   - Positive values mean the row distribution has larger Δ on average.

Interpretation:
- If Gibbs and SA are similar, their AUC should be near 0.5 and Δ mean near 0.
- If SA drifts away, AUC or Δ mean will highlight that separation from Gibbs/MD.

## β_eff scan

Plots the distance between SA samples and Gibbs samples across a β grid.

- **Minimum point** = `β_eff`, the Gibbs temperature that best matches SA.
- If the curve is flat → SA is not close to any Gibbs β (sampler bias).
- If the minimum is sharp → SA corresponds to a well-defined effective temperature.

## Nearest-neighbor (NN) CDFs

Two CDFs are shown:
- **Sample → MD**: how close each sample is to *some* MD frame (precision proxy).
- **MD → Sample**: how well the sample set covers MD (coverage/recall proxy).

Interpretation:
- High Sample→MD but low MD→Sample means collapse onto a few MD modes.
- Good Gibbs runs should balance both curves.

## What to check first (quick triage)

1) **Residue barcode** and **edge barcode**: locate the main mismatches.
2) **Energy histogram**: see if SA is simply too hot.
3) **β_eff scan**: check if SA corresponds to any Gibbs temperature.
4) **Cross-likelihood**: verify that SA preserves separability patterns.

If Gibbs vs MD is poor, fix clustering/model before interpreting SA.
